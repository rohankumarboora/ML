import pandas as pd
 from sklearn.model_selection import train_test_split
 from sklearn.linear_model import LinearRegression
 from sklearn.metrics import mean_squared_error, r2_score
 import matplotlib.pyplot as plt
 df = pd.read_csv(r'/home/anaconda/Downloads/Boston (1).csv')
 df.head()
 feature_cols = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age','dis', 'rad', 'tax', 'ptratio', 'black', 
X = df[feature_cols]
 y = df['medv']
 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
 lr = LinearRegression()
 lr.fit(X_train, y_train)
 y_pred = lr.predict(X_test)
 print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
 print("R^2 Score:", r2_score(y_test, y_pred))
 # Print regression coefficients
 print("Intercept:", lr.intercept_)
 for feat, coef in zip(feature_cols, lr.coef_):
    print(f"{feat}  : {coef}")
 plt.figure(figsize=(8,6))
 plt.scatter(y_test, y_pred, alpha=0.6)
 plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)
 plt.xlabel('Actual')
 plt.ylabel('Predicted')
 plt.title('Actual vs Predicted Values - Linear Regression')
 plt.grid(True)
 plt.show()
